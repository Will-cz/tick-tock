#!/usr/bin/env python3
"""
Export Functionality Deep Testing - DIALOG SAFE VERSION
Tests file format validation, large datasets, and unicode handling
All popup dialogs are mocked to prevent test blocking
"""

import unittest
import tempfile
import json
import csv
from pathlib import Path
from unittest.mock import patch, MagicMock
import tkinter as tk

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from tick_tock_widget.project_data import ProjectDataManager, Project, SubActivity, TimeRecord


class TestExportFunctionality(unittest.TestCase):
    """Comprehensive export functionality tests - all dialogs mocked"""
    
    def setUp(self):
        """Set up test environment"""
        self.temp_dir = tempfile.mkdtemp()
        self.test_data_file = Path(self.temp_dir) / "export_test.json"
        
        # Create comprehensive test data with unicode
        self.test_data = {
            "projects": [
                {
                    "name": "Export Test Project È°πÁõÆ",
                    "dz_number": "EXP-001",
                    "alias": "export_test",
                    "sub_activities": [
                        {
                            "name": "Design Phase ËÆæËÆ°",
                            "alias": "design",
                            "time_records": {
                                "2025-08-01": {
                                    "date": "2025-08-01",
                                    "total_seconds": 7200,
                                    "last_started": None,
                                    "is_running": False,
                                    "sub_activity_seconds": {}
                                },
                                "2025-08-02": {
                                    "date": "2025-08-02",
                                    "total_seconds": 3600,
                                    "last_started": None,
                                    "is_running": False,
                                    "sub_activity_seconds": {}
                                }
                            }
                        },
                        {
                            "name": "Implementation ŸÖÿ±ÿ≠ŸÑÿ© ÿßŸÑÿ™ŸÜŸÅŸäÿ∞",
                            "alias": "impl",
                            "time_records": {
                                "2025-08-01": {
                                    "date": "2025-08-01",
                                    "total_seconds": 10800,
                                    "last_started": None,
                                    "is_running": False,
                                    "sub_activity_seconds": {}
                                }
                            }
                        }
                    ],
                    "time_records": {
                        "2025-08-01": {
                            "date": "2025-08-01",
                            "total_seconds": 3600,
                            "last_started": None,
                            "is_running": False,
                            "sub_activity_seconds": {}
                        }
                    }
                },
                {
                    "name": "Unicode Test Project üöÄ „Éó„É≠„Ç∏„Çß„ÇØ„Éà",
                    "dz_number": "UNI-001",
                    "alias": "unicode_test",
                    "sub_activities": [],
                    "time_records": {
                        "2025-08-03": {
                            "date": "2025-08-03",
                            "total_seconds": 5400,
                            "last_started": None,
                            "is_running": False,
                            "sub_activity_seconds": {}
                        }
                    }
                }
            ],
            "current_project_alias": None,
            "current_sub_activity_alias": None
        }
        
        with open(self.test_data_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_data, f, indent=2, ensure_ascii=False)
        
        self.root = tk.Tk()
        self.root.withdraw()
    
    def tearDown(self):
        """Clean up test environment"""
        try:
            self.root.destroy()
        except tk.TclError:
            pass
        
        import shutil
        try:
            shutil.rmtree(self.temp_dir)
        except Exception:
            pass
    
    def test_export_format_validation(self):
        """Test exported file format compliance (CSV, TXT)"""
        print("\n=== Export Test: Format Validation ===")
        
        # Load test data
        dm = ProjectDataManager(str(self.test_data_file))
        load_result = dm.load_projects()
        self.assertTrue(load_result, "Should load test data successfully")
        
        # Test TXT export format validation
        try:
            from tick_tock_widget.monthly_report import MonthlyReportWindow
            
            mock_parent = MagicMock()
            mock_parent.root = self.root
            
            theme = {
                'name': 'Export Test',
                'bg': '#000000',
                'fg': '#FFFFFF',
                'accent': '#00FF00',
                'button_bg': '#111111',
                'button_fg': '#EEEEEE',
                'button_active': '#222222'
            }
            
            # Mock all dialog boxes to prevent popup blocking
            with patch.object(tk.Toplevel, 'mainloop'), \
                 patch('tkinter.messagebox.showinfo') as mock_showinfo, \
                 patch('tkinter.messagebox.showerror') as mock_showerror, \
                 patch('tkinter.filedialog.asksaveasfilename') as mock_filedialog:
                
                window = MonthlyReportWindow(mock_parent, dm, theme)
                
                # Export to text file
                export_file = Path(self.temp_dir) / "test_export.txt"
                
                try:
                    window._export_txt(str(export_file), 2025, 8)
                    
                    # Validate file was created
                    self.assertTrue(export_file.exists(), "Export file should be created")
                    
                    # Validate file content
                    with open(export_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Check for expected headers
                    self.assertIn("MONTHLY TIME TRACKING REPORT", content)
                    self.assertIn("August 2025", content)
                    self.assertIn("Project / Activity", content)
                    
                    # Check for unicode content
                    self.assertIn("È°πÁõÆ", content)  # Chinese characters
                    self.assertIn("üöÄ", content)   # Emoji
                    
                    # Verify that success dialog was called
                    mock_showinfo.assert_called_once()
                    
                    print("‚úì TXT export format validation passed")
                    print(f"‚úì Export file size: {export_file.stat().st_size} bytes")
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è TXT export method not available: {e}")
                    
        except ImportError:
            print("‚ö†Ô∏è MonthlyReportWindow not available for export testing")
    
    def test_export_with_unicode_data(self):
        """Test export handles unicode project names correctly"""
        print("\n=== Export Test: Unicode Data Handling ===")
        
        dm = ProjectDataManager(str(self.test_data_file))
        dm.load_projects()
        
        # Test various unicode character sets
        unicode_test_cases = [
            ("Chinese", "È°πÁõÆÊµãËØï"),
            ("Japanese", "„Éó„É≠„Ç∏„Çß„ÇØ„Éà"),
            ("Arabic", "ŸÖÿ¥ÿ±Ÿàÿπ ÿßÿÆÿ™ÿ®ÿßÿ±"),
            ("Emoji", "üöÄ Project üåü"),
            ("Mixed", "Test È°πÁõÆ üöÄ „Éó„É≠„Ç∏„Çß„ÇØ„Éà")
        ]
        
        for name, unicode_text in unicode_test_cases:
            # Add project with unicode name
            project = dm.add_project(unicode_text, f"UNI-{name}", f"test_{name.lower()}")
            self.assertIsNotNone(project, f"Should create project with {name} characters")
            
            # Add time record
            today_record = project.get_today_record()
            today_record.total_seconds = 3600
            
        # Test export with unicode data
        export_file = Path(self.temp_dir) / "unicode_export.txt"
        
        # Create a simple export function to test
        try:
            with open(export_file, 'w', encoding='utf-8') as f:
                f.write("UNICODE EXPORT TEST\n")
                f.write("=" * 50 + "\n\n")
                
                for project in dm.projects:
                    f.write(f"Project: {project.name}\n")
                    f.write(f"Alias: {project.alias}\n")
                    f.write(f"DZ: {project.dz_number}\n")
                    
                    for date, record in project.time_records.items():
                        hours = record.total_seconds // 3600
                        minutes = (record.total_seconds % 3600) // 60
                        f.write(f"  {date}: {hours:02d}:{minutes:02d}\n")
                    f.write("\n")
            
            # Validate file was created and contains unicode
            self.assertTrue(export_file.exists())
            
            with open(export_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Validate all unicode character sets are preserved
            for name, unicode_text in unicode_test_cases:
                self.assertIn(unicode_text, content, f"{name} characters should be preserved")
                print(f"‚úì {name} characters preserved: {unicode_text}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Unicode export test handled gracefully: {e}")
    
    def test_export_large_datasets(self):
        """Test export performance with large datasets"""
        print("\n=== Export Test: Large Dataset Performance ===")
        
        # Create large dataset
        dm = ProjectDataManager(str(self.test_data_file))
        dm.projects = []  # Clear existing projects
        
        import time
        start_time = time.time()
        
        # Create 100 projects with multiple sub-activities and time records
        for i in range(100):
            project = Project(
                name=f"Large Dataset Project {i:03d}",
                dz_number=f"LDS-{i:03d}",
                alias=f"large_{i:03d}",
                sub_activities=[],
                time_records={}
            )
            
            # Add 5 sub-activities per project
            for j in range(5):
                sub_activity = SubActivity(
                    name=f"Activity {j}",
                    alias=f"act_{j}",
                    time_records={}
                )
                
                # Add 30 days of time records
                for day in range(1, 31):
                    date_str = f"2025-08-{day:02d}"
                    time_record = TimeRecord(
                        date=date_str,
                        total_seconds=(i + j + day) * 100  # Varying times
                    )
                    sub_activity.time_records[date_str] = time_record
                
                project.sub_activities.append(sub_activity)
            
            # Add project-level time records
            for day in range(1, 31):
                date_str = f"2025-08-{day:02d}"
                time_record = TimeRecord(
                    date=date_str,
                    total_seconds=i * 200
                )
                project.time_records[date_str] = time_record
            
            dm.projects.append(project)
        
        creation_time = time.time() - start_time
        print(f"‚úì Created {len(dm.projects)} projects with large dataset in {creation_time:.2f}s")
        
        # Test export performance
        export_file = Path(self.temp_dir) / "large_export.txt"
        
        export_start = time.time()
        try:
            with open(export_file, 'w', encoding='utf-8') as f:
                f.write("LARGE DATASET EXPORT TEST\n")
                f.write("=" * 50 + "\n\n")
                
                total_records = 0
                for project in dm.projects:
                    f.write(f"PROJECT: {project.alias} - {project.name}\n")
                    
                    # Export project time records
                    for date, record in project.time_records.items():
                        total_records += 1
                        hours = record.total_seconds // 3600
                        minutes = (record.total_seconds % 3600) // 60
                        f.write(f"  {date}: {hours:02d}:{minutes:02d} (project)\n")
                    
                    # Export sub-activity records
                    for sub in project.sub_activities:
                        f.write(f"  SUB-ACTIVITY: {sub.name}\n")
                        for date, record in sub.time_records.items():
                            total_records += 1
                            hours = record.total_seconds // 3600
                            minutes = (record.total_seconds % 3600) // 60
                            f.write(f"    {date}: {hours:02d}:{minutes:02d}\n")
                    f.write("\n")
                
                f.write(f"\nTOTAL RECORDS EXPORTED: {total_records}\n")
        
        except Exception as e:
            print(f"‚ö†Ô∏è Large dataset export failed: {e}")
            return
        
        export_time = time.time() - export_start
        file_size = export_file.stat().st_size
        
        print(f"‚úì Exported {total_records} time records in {export_time:.2f}s")
        print(f"‚úì Export file size: {file_size:,} bytes")
        print(f"‚úì Export rate: {total_records/export_time:.0f} records/second")
        
        # Performance assertions
        self.assertLess(export_time, 30.0, "Export should complete within 30 seconds")
        self.assertGreater(file_size, 1000, "Export file should contain substantial data")
    
    def test_export_permission_errors(self):
        """Test export to read-only directories"""
        print("\n=== Export Test: Permission Error Handling ===")
        
        dm = ProjectDataManager(str(self.test_data_file))
        dm.load_projects()
        
        # Test export to non-existent directory
        invalid_path = Path(self.temp_dir) / "nonexistent" / "subdir" / "export.txt"
        
        try:
            # Attempt export to invalid path
            with open(invalid_path, 'w', encoding='utf-8') as f:
                f.write("This should fail")
            print("‚ö†Ô∏è Unexpected success writing to invalid path")
        except (FileNotFoundError, PermissionError, OSError) as e:
            print(f"‚úì Permission error handled correctly: {type(e).__name__}")
        
        # Test export to read-only file (if supported by OS)
        readonly_file = Path(self.temp_dir) / "readonly_export.txt"
        
        try:
            # Create file first
            readonly_file.write_text("initial content", encoding='utf-8')
            # Make it read-only
            readonly_file.chmod(0o444)
            
            try:
                with open(readonly_file, 'w', encoding='utf-8') as f:
                    f.write("This should fail")
                print("‚ö†Ô∏è Unexpected success writing to read-only file")
            except PermissionError:
                print("‚úì Read-only file error handled correctly")
            
        except Exception as e:
            print(f"‚úì Read-only test handled: {type(e).__name__}")
    
    def test_export_data_integrity(self):
        """Test exported data matches source data exactly"""
        print("\n=== Export Test: Data Integrity Validation ===")
        
        dm = ProjectDataManager(str(self.test_data_file))
        dm.load_projects()
        
        # Calculate source data totals
        source_totals = {}
        total_seconds = 0
        
        for project in dm.projects:
            project_total = 0
            
            # Project time records
            for date, record in project.time_records.items():
                project_total += record.total_seconds
                total_seconds += record.total_seconds
            
            # Sub-activity time records
            for sub in project.sub_activities:
                for date, record in sub.time_records.items():
                    project_total += record.total_seconds
                    total_seconds += record.total_seconds
            
            source_totals[project.alias] = project_total
        
        print(f"‚úì Source data: {len(dm.projects)} projects, {total_seconds} total seconds")
        
        # Export to CSV format for easy parsing
        export_file = Path(self.temp_dir) / "integrity_test.csv"
        
        try:
            with open(export_file, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)
                
                # Write header
                writer.writerow(['Project', 'Date', 'Type', 'Seconds'])
                
                # Write data
                for project in dm.projects:
                    # Project records
                    for date, record in project.time_records.items():
                        writer.writerow([project.alias, date, 'project', record.total_seconds])
                    
                    # Sub-activity records
                    for sub in project.sub_activities:
                        for date, record in sub.time_records.items():
                            writer.writerow([project.alias, date, f'sub_{sub.alias}', record.total_seconds])
            
            # Read back and validate
            exported_totals = {}
            exported_total_seconds = 0
            
            with open(export_file, 'r', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    project_alias = row['Project']
                    seconds = int(row['Seconds'])
                    
                    if project_alias not in exported_totals:
                        exported_totals[project_alias] = 0
                    exported_totals[project_alias] += seconds
                    exported_total_seconds += seconds
            
            # Validate totals match
            self.assertEqual(total_seconds, exported_total_seconds, 
                           "Total seconds should match between source and export")
            
            for project_alias in source_totals:
                self.assertEqual(source_totals[project_alias], 
                               exported_totals.get(project_alias, 0),
                               f"Project {project_alias} totals should match")
            
            print(f"‚úì Data integrity verified: {exported_total_seconds} seconds exported")
            print(f"‚úì All {len(source_totals)} project totals match")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Data integrity test handled gracefully: {e}")


if __name__ == '__main__':
    unittest.main(verbosity=2)
