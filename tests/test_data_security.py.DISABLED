#!/usr/bin/env python3
"""
Data Security Testing - Phase 2
Tests data integrity, encryption simulation, and security measures
"""

import unittest
import tempfile
import json
import os
import hashlib
import shutil
import time
from pathlib import Path
from unittest.mock import patch, MagicMock

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from tick_tock_widget.project_data import ProjectDataManager, Project, TimeRecord


class TestDataSecurity(unittest.TestCase):
    """Test data security and integrity measures"""
    
    def setUp(self):
        """Set up security testing environment"""
        self.temp_dir = tempfile.mkdtemp()
        self.test_data_file = Path(self.temp_dir) / "security_test.json"
        self.backup_dir = Path(self.temp_dir) / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        
        print(f"\nüîí Security Test Setup:")
        print(f"   Test Directory: {self.temp_dir}")
        print(f"   Backup Directory: {self.backup_dir}")
    
    def tearDown(self):
        """Clean up security test environment"""
        try:
            shutil.rmtree(self.temp_dir)
        except Exception:
            pass
    
    def test_data_integrity_validation(self):
        """Test data integrity checks and validation"""
        print("\n=== Security Test: Data Integrity Validation ===")
        
        # Create valid test data
        valid_data = {
            "projects": [
                {
                    "name": "Security Test Project",
                    "dz_number": "SEC-001",
                    "alias": "sec_001",
                    "sub_activities": [],
                    "time_records": {
                        "2025-08-09": {
                            "date": "2025-08-09",
                            "total_seconds": 3600,
                            "last_started": None,
                            "is_running": False,
                            "sub_activity_seconds": {}
                        }
                    }
                }
            ],
            "current_project_alias": None,
            "current_sub_activity_alias": None
        }
        
        with open(self.test_data_file, 'w', encoding='utf-8') as f:
            json.dump(valid_data, f, indent=2)
        
        # Calculate original checksum
        original_checksum = self._calculate_file_checksum(self.test_data_file)
        
        # Test 1: Valid data loading
        dm = ProjectDataManager(str(self.test_data_file))
        load_success = dm.load_projects()
        
        self.assertTrue(load_success, "Should load valid data successfully")
        self.assertEqual(len(dm.projects), 1, "Should load exactly one project")
        
        print(f"‚úì Original checksum: {original_checksum[:16]}...")
        print(f"‚úì Valid data loaded successfully")
        
        # Test 2: Data corruption detection
        print("\n--- Testing Data Corruption Detection ---")
        
        # Create corrupted data files
        corruption_tests = [
            {
                "name": "Invalid JSON syntax",
                "data": '{"projects": [invalid json}',
                "should_load": False
            },
            {
                "name": "Missing required fields",
                "data": '{"projects": [{"name": "Test"}]}',
                "should_load": False
            },
            {
                "name": "Invalid data types",
                "data": '{"projects": "not_a_list", "current_project_alias": null}',
                "should_load": False
            },
            {
                "name": "Malformed time records",
                "data": json.dumps({
                    "projects": [{
                        "name": "Test",
                        "dz_number": "TEST-001",
                        "alias": "test",
                        "sub_activities": [],
                        "time_records": {
                            "invalid_date": {
                                "date": "not-a-date",
                                "total_seconds": "not_a_number",
                                "last_started": None,
                                "is_running": False,
                                "sub_activity_seconds": {}
                            }
                        }
                    }],
                    "current_project_alias": None,
                    "current_sub_activity_alias": None
                }),
                "should_load": True  # May load but should handle gracefully
            }
        ]
        
        for test_case in corruption_tests:
            corrupted_file = Path(self.temp_dir) / f"corrupted_{test_case['name'].replace(' ', '_')}.json"
            
            with open(corrupted_file, 'w', encoding='utf-8') as f:
                f.write(test_case['data'])
            
            dm_corrupted = ProjectDataManager(str(corrupted_file))
            load_result = dm_corrupted.load_projects()
            
            if test_case['should_load']:
                print(f"‚úì {test_case['name']}: Handled gracefully (load={load_result})")
            else:
                self.assertFalse(load_result, f"Should reject: {test_case['name']}")
                print(f"‚úì {test_case['name']}: Correctly rejected")
        
        # Test 3: File permission security
        print("\n--- Testing File Permission Security ---")
        
        # Test read-only file handling
        readonly_file = Path(self.temp_dir) / "readonly_test.json"
        with open(readonly_file, 'w', encoding='utf-8') as f:
            json.dump(valid_data, f)
        
        # Make file read-only (Windows compatible)
        try:
            readonly_file.chmod(0o444)  # Read-only permissions
            
            dm_readonly = ProjectDataManager(str(readonly_file))
            load_result = dm_readonly.load_projects()
            
            self.assertTrue(load_result, "Should read from read-only file")
            print("‚úì Read-only file: Successfully read")
            
            # Try to save to read-only file (should fail gracefully)
            if hasattr(dm_readonly, 'save_projects'):
                try:
                    save_result = dm_readonly.save_projects()
                    print(f"‚úì Read-only save attempt: {save_result}")
                except Exception as e:
                    print(f"‚úì Read-only save attempt: Handled exception ({type(e).__name__})")
            
        except OSError as e:
            print(f"‚ÑπÔ∏è Permission test skipped: {e}")
        finally:
            # Reset permissions for cleanup
            try:
                readonly_file.chmod(0o666)
            except:
                pass
    
    def test_backup_and_recovery_system(self):
        """Test automated backup and recovery mechanisms"""
        print("\n=== Security Test: Backup and Recovery System ===")
        
        # Create primary data
        primary_data = {
            "projects": [
                {
                    "name": "Backup Test Project 1",
                    "dz_number": "BKP-001",
                    "alias": "bkp_001",
                    "sub_activities": [],
                    "time_records": {
                        "2025-08-09": {
                            "date": "2025-08-09",
                            "total_seconds": 7200,
                            "last_started": None,
                            "is_running": False,
                            "sub_activity_seconds": {}
                        }
                    }
                },
                {
                    "name": "Backup Test Project 2",
                    "dz_number": "BKP-002",
                    "alias": "bkp_002",
                    "sub_activities": [],
                    "time_records": {}
                }
            ],
            "current_project_alias": "bkp_001",
            "current_sub_activity_alias": None
        }
        
        with open(self.test_data_file, 'w', encoding='utf-8') as f:
            json.dump(primary_data, f, indent=2)
        
        original_checksum = self._calculate_file_checksum(self.test_data_file)
        
        # Test 1: Create backup
        backup_file = self.backup_dir / f"backup_{int(time.time())}.json"
        shutil.copy2(self.test_data_file, backup_file)
        
        backup_checksum = self._calculate_file_checksum(backup_file)
        
        self.assertEqual(original_checksum, backup_checksum, "Backup should match original")
        print(f"‚úì Backup created: {backup_file.name}")
        print(f"‚úì Checksum verified: {original_checksum[:16]}...")
        
        # Test 2: Simulate data corruption and recovery
        print("\n--- Testing Recovery from Corruption ---")
        
        # Corrupt the primary file
        with open(self.test_data_file, 'w', encoding='utf-8') as f:
            f.write("corrupted data{invalid json")
        
        corrupted_checksum = self._calculate_file_checksum(self.test_data_file)
        self.assertNotEqual(original_checksum, corrupted_checksum, "File should be corrupted")
        
        # Attempt to load corrupted data
        dm_corrupted = ProjectDataManager(str(self.test_data_file))
        load_result = dm_corrupted.load_projects()
        
        self.assertFalse(load_result, "Should fail to load corrupted data")
        print("‚úì Corrupted data correctly rejected")
        
        # Simulate recovery from backup
        shutil.copy2(backup_file, self.test_data_file)
        recovered_checksum = self._calculate_file_checksum(self.test_data_file)
        
        self.assertEqual(original_checksum, recovered_checksum, "Recovery should restore original data")
        
        # Verify recovered data loads correctly
        dm_recovered = ProjectDataManager(str(self.test_data_file))
        recovery_success = dm_recovered.load_projects()
        
        self.assertTrue(recovery_success, "Should load recovered data successfully")
        self.assertEqual(len(dm_recovered.projects), 2, "Should recover all projects")
        
        print("‚úì Data successfully recovered from backup")
        print(f"‚úì Recovered {len(dm_recovered.projects)} projects")
        
        # Test 3: Multiple backup versions
        print("\n--- Testing Multiple Backup Versions ---")
        
        backup_versions = []
        
        for i in range(3):
            # Modify data slightly
            modified_data = primary_data.copy()
            modified_data['projects'][0]['time_records'][f"2025-08-0{i+1}"] = {
                "date": f"2025-08-0{i+1}",
                "total_seconds": 1800 * (i + 1),
                "last_started": None,
                "is_running": False,
                "sub_activity_seconds": {}
            }
            
            # Save modified version
            version_file = self.backup_dir / f"version_{i+1}.json"
            with open(version_file, 'w', encoding='utf-8') as f:
                json.dump(modified_data, f, indent=2)
            
            version_checksum = self._calculate_file_checksum(version_file)
            backup_versions.append({
                'file': version_file,
                'checksum': version_checksum,
                'version': i + 1
            })
            
            print(f"‚úì Version {i+1} backup: {version_checksum[:16]}...")
        
        # Verify all versions are different
        checksums = [v['checksum'] for v in backup_versions]
        self.assertEqual(len(set(checksums)), len(checksums), "All backup versions should be unique")
        
        # Test recovery from specific version
        recovery_version = backup_versions[1]  # Middle version
        shutil.copy2(recovery_version['file'], self.test_data_file)
        
        dm_version_recovery = ProjectDataManager(str(self.test_data_file))
        version_load_success = dm_version_recovery.load_projects()
        
        self.assertTrue(version_load_success, "Should load specific version successfully")
        print(f"‚úì Successfully recovered from version {recovery_version['version']}")
    
    def test_data_validation_and_sanitization(self):
        """Test input validation and data sanitization"""
        print("\n=== Security Test: Data Validation and Sanitization ===")
        
        # Test 1: Input validation for project data
        print("\n--- Testing Input Validation ---")
        
        validation_tests = [
            {
                "name": "SQL injection attempt",
                "project_name": "'; DROP TABLE projects; --",
                "should_accept": True,  # Should accept but sanitize
                "expected_clean": "'; DROP TABLE projects; --"  # Stored as-is but handled safely
            },
            {
                "name": "XSS attempt",
                "project_name": "<script>alert('xss')</script>",
                "should_accept": True,
                "expected_clean": "<script>alert('xss')</script>"
            },
            {
                "name": "Path traversal attempt",
                "project_name": "../../../etc/passwd",
                "should_accept": True,
                "expected_clean": "../../../etc/passwd"
            },
            {
                "name": "Unicode normalization",
                "project_name": "Caf√© M√ºnchen",
                "should_accept": True,
                "expected_clean": "Caf√© M√ºnchen"
            },
            {
                "name": "Long input test",
                "project_name": "A" * 1000,
                "should_accept": True,
                "expected_clean": "A" * 1000
            },
            {
                "name": "Null bytes",
                "project_name": "Test\x00Project",
                "should_accept": True,
                "expected_clean": "Test\x00Project"
            }
        ]
        
        dm = ProjectDataManager(str(self.test_data_file))
        
        for test_case in validation_tests:
            try:
                # Create project with potentially dangerous input
                project = Project(
                    name=test_case['project_name'],
                    dz_number="VALID-001",
                    alias="test_alias"
                )
                
                # Verify the project was created
                self.assertIsNotNone(project, f"Should create project for: {test_case['name']}")
                
                # Check if the name was stored correctly
                stored_name = project.name
                
                if test_case['should_accept']:
                    print(f"‚úì {test_case['name']}: Accepted and stored")
                else:
                    self.fail(f"Should have rejected: {test_case['name']}")
                    
            except Exception as e:
                if not test_case['should_accept']:
                    print(f"‚úì {test_case['name']}: Correctly rejected ({type(e).__name__})")
                else:
                    print(f"‚ö†Ô∏è {test_case['name']}: Unexpected rejection ({e})")
        
        # Test 2: Date validation
        print("\n--- Testing Date Validation ---")
        
        date_tests = [
            {
                "date": "2025-08-09",
                "valid": True,
                "description": "Valid ISO date"
            },
            {
                "date": "2025-13-45",
                "valid": False,
                "description": "Invalid month and day"
            },
            {
                "date": "not-a-date",
                "valid": False,
                "description": "Non-date string"
            },
            {
                "date": "2025/08/09",
                "valid": False,
                "description": "Wrong date format"
            },
            {
                "date": "",
                "valid": False,
                "description": "Empty date"
            }
        ]
        
        for test_case in date_tests:
            try:
                # Create time record with test date
                time_record = TimeRecord(
                    date=test_case['date'],
                    total_seconds=3600
                )
                
                if test_case['valid']:
                    print(f"‚úì {test_case['description']}: Accepted")
                else:
                    print(f"‚ö†Ô∏è {test_case['description']}: Unexpectedly accepted")
                    
            except Exception as e:
                if not test_case['valid']:
                    print(f"‚úì {test_case['description']}: Correctly rejected")
                else:
                    print(f"‚ö†Ô∏è {test_case['description']}: Unexpectedly rejected ({e})")
        
        # Test 3: Numeric validation
        print("\n--- Testing Numeric Validation ---")
        
        numeric_tests = [
            {"seconds": 3600, "valid": True, "description": "Valid positive seconds"},
            {"seconds": 0, "valid": True, "description": "Zero seconds"},
            {"seconds": -1, "valid": False, "description": "Negative seconds"},
            {"seconds": 999999999, "valid": True, "description": "Very large seconds"},
            {"seconds": "3600", "valid": False, "description": "String seconds"},
            {"seconds": 3600.5, "valid": True, "description": "Float seconds"},
        ]
        
        for test_case in numeric_tests:
            try:
                time_record = TimeRecord(
                    date="2025-08-09",
                    total_seconds=test_case['seconds']
                )
                
                if test_case['valid']:
                    print(f"‚úì {test_case['description']}: Accepted")
                else:
                    print(f"‚ö†Ô∏è {test_case['description']}: Unexpectedly accepted")
                    
            except Exception as e:
                if not test_case['valid']:
                    print(f"‚úì {test_case['description']}: Correctly rejected")
                else:
                    print(f"‚ö†Ô∏è {test_case['description']}: Unexpectedly rejected ({e})")
    
    def test_access_control_simulation(self):
        """Test access control and permission systems"""
        print("\n=== Security Test: Access Control Simulation ===")
        
        # Create test data file
        test_data = {
            "projects": [
                {
                    "name": "Access Control Test",
                    "dz_number": "ACC-001",
                    "alias": "acc_001",
                    "sub_activities": [],
                    "time_records": {
                        "2025-08-09": {
                            "date": "2025-08-09",
                            "total_seconds": 3600,
                            "last_started": None,
                            "is_running": False,
                            "sub_activity_seconds": {}
                        }
                    }
                }
            ],
            "current_project_alias": None,
            "current_sub_activity_alias": None
        }
        
        with open(self.test_data_file, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, indent=2)
        
        # Test 1: File existence verification
        print("\n--- Testing File Access Patterns ---")
        
        dm = ProjectDataManager(str(self.test_data_file))
        
        # Verify file exists before attempting access
        self.assertTrue(self.test_data_file.exists(), "Test file should exist")
        
        # Test read access
        read_success = dm.load_projects()
        self.assertTrue(read_success, "Should have read access to file")
        print("‚úì Read access: Successful")
        
        # Test 2: Simulate different user contexts
        print("\n--- Testing User Context Simulation ---")
        
        # Simulate admin context (full access)
        with patch.dict(os.environ, {'USER_ROLE': 'admin'}):
            admin_dm = ProjectDataManager(str(self.test_data_file))
            admin_load = admin_dm.load_projects()
            self.assertTrue(admin_load, "Admin should have full access")
            print("‚úì Admin context: Full access granted")
        
        # Simulate read-only context
        with patch.dict(os.environ, {'USER_ROLE': 'readonly'}):
            readonly_dm = ProjectDataManager(str(self.test_data_file))
            readonly_load = readonly_dm.load_projects()
            self.assertTrue(readonly_load, "Read-only user should have read access")
            print("‚úì Read-only context: Read access granted")
        
        # Test 3: File locking simulation
        print("\n--- Testing File Locking Simulation ---")
        
        # Simulate concurrent access
        lock_file = Path(self.temp_dir) / "test.lock"
        
        def simulate_file_operation(operation_id, duration=0.1):
            """Simulate a file operation with locking"""
            try:
                # Check if lock exists
                if lock_file.exists():
                    return {"id": operation_id, "status": "blocked", "reason": "file_locked"}
                
                # Create lock
                with open(lock_file, 'w') as f:
                    f.write(f"locked_by_{operation_id}")
                
                # Simulate operation
                time.sleep(duration)
                
                # Release lock
                lock_file.unlink()
                
                return {"id": operation_id, "status": "success", "reason": "completed"}
                
            except Exception as e:
                return {"id": operation_id, "status": "error", "reason": str(e)}
        
        # Test sequential operations
        result1 = simulate_file_operation("op1")
        result2 = simulate_file_operation("op2")
        
        self.assertEqual(result1['status'], "success", "First operation should succeed")
        self.assertEqual(result2['status'], "success", "Second operation should succeed after first")
        
        print("‚úì Sequential file operations: Both successful")
        print(f"   Operation 1: {result1['status']}")
        print(f"   Operation 2: {result2['status']}")
        
        # Test 4: Path traversal protection
        print("\n--- Testing Path Traversal Protection ---")
        
        dangerous_paths = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "/etc/shadow",
            "C:\\Windows\\System32\\config\\SAM",
            "data/../../../sensitive.txt"
        ]
        
        for dangerous_path in dangerous_paths:
            try:
                # This should either be blocked or safely handled
                normalized_path = Path(dangerous_path).resolve()
                
                # Check if path escapes intended directory
                temp_dir_resolved = Path(self.temp_dir).resolve()
                
                try:
                    normalized_path.relative_to(temp_dir_resolved)
                    print(f"‚úì Path {dangerous_path}: Safely contained")
                except ValueError:
                    print(f"‚úì Path {dangerous_path}: Outside bounds (safely detected)")
                    
            except Exception as e:
                print(f"‚úì Path {dangerous_path}: Safely rejected ({type(e).__name__})")
    
    def _calculate_file_checksum(self, file_path):
        """Calculate SHA-256 checksum of a file"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()


if __name__ == '__main__':
    unittest.main(verbosity=2)
