#!/usr/bin/env python3
"""
Automated Qualification Tests (AQT) for Tick-Tock Widget
End-to-end testing that simulates real user workflows
"""

import unittest
import tempfile
import json
import time
from pathlib import Path
from unittest.mock import patch, MagicMock
import tkinter as tk

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from tick_tock_widget.tick_tock_widget import TickTockWidget
from tick_tock_widget.project_data import ProjectDataManager
from tick_tock_widget.project_management import ProjectManagementWindow


class TestAutomatedQualification(unittest.TestCase):
    """Automated Qualification Tests simulating real user scenarios"""
    
    def setUp(self):
        """Set up realistic test environment"""
        self.temp_dir = tempfile.mkdtemp()
        self.test_data_file = Path(self.temp_dir) / "aqt_projects.json"
        
        # Create realistic project data similar to production
        self.realistic_data = {
            "projects": [
                {
                    "name": "NFC Payment System",
                    "dz_number": "NFC-2025-001",
                    "alias": "NFC",
                    "sub_activities": [
                        {
                            "name": "Requirements Analysis",
                            "alias": "analysis",
                            "time_records": {
                                "2025-08-01": {"date": "2025-08-01", "total_seconds": 14400, "last_started": None, "is_running": False, "sub_activity_seconds": {}},
                                "2025-08-02": {"date": "2025-08-02", "total_seconds": 10800, "last_started": None, "is_running": False, "sub_activity_seconds": {}},
                                "2025-08-05": {"date": "2025-08-05", "total_seconds": 18000, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                            }
                        },
                        {
                            "name": "Implementation",
                            "alias": "impl",
                            "time_records": {
                                "2025-08-01": {"date": "2025-08-01", "total_seconds": 25200, "last_started": None, "is_running": False, "sub_activity_seconds": {}},
                                "2025-08-02": {"date": "2025-08-02", "total_seconds": 28800, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                            }
                        },
                        {
                            "name": "Testing & QA",
                            "alias": "testing",
                            "time_records": {
                                "2025-08-03": {"date": "2025-08-03", "total_seconds": 21600, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                            }
                        }
                    ],
                    "time_records": {
                        "2025-08-01": {"date": "2025-08-01", "total_seconds": 7200, "last_started": None, "is_running": False, "sub_activity_seconds": {}},
                        "2025-08-02": {"date": "2025-08-02", "total_seconds": 5400, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                    }
                },
                {
                    "name": "Dashboard UI Redesign",
                    "dz_number": "DASH-2025-002",
                    "alias": "DASH",
                    "sub_activities": [
                        {
                            "name": "UI Design",
                            "alias": "design",
                            "time_records": {
                                "2025-08-04": {"date": "2025-08-04", "total_seconds": 16200, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                            }
                        },
                        {
                            "name": "Frontend Development",
                            "alias": "frontend",
                            "time_records": {
                                "2025-08-05": {"date": "2025-08-05", "total_seconds": 32400, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                            }
                        }
                    ],
                    "time_records": {
                        "2025-08-04": {"date": "2025-08-04", "total_seconds": 3600, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                    }
                },
                {
                    "name": "Admin & Meeting Time",
                    "dz_number": "ADM-2025-003",
                    "alias": "ADMIN",
                    "sub_activities": [
                        {
                            "name": "Daily Standups",
                            "alias": "standups",
                            "time_records": {
                                "2025-08-01": {"date": "2025-08-01", "total_seconds": 1800, "last_started": None, "is_running": False, "sub_activity_seconds": {}},
                                "2025-08-02": {"date": "2025-08-02", "total_seconds": 1800, "last_started": None, "is_running": False, "sub_activity_seconds": {}},
                                "2025-08-05": {"date": "2025-08-05", "total_seconds": 1800, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                            }
                        },
                        {
                            "name": "Documentation",
                            "alias": "docs",
                            "time_records": {
                                "2025-08-03": {"date": "2025-08-03", "total_seconds": 5400, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                            }
                        }
                    ],
                    "time_records": {
                        "2025-08-01": {"date": "2025-08-01", "total_seconds": 3600, "last_started": None, "is_running": False, "sub_activity_seconds": {}},
                        "2025-08-03": {"date": "2025-08-03", "total_seconds": 1800, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                    }
                }
            ],
            "current_project_alias": None,
            "current_sub_activity_alias": None
        }
        
        # Write realistic data to file
        with open(self.test_data_file, 'w', encoding='utf-8') as f:
            json.dump(self.realistic_data, f, indent=2)
        
        self.root = tk.Tk()
        self.root.withdraw()
    
    def tearDown(self):
        """Clean up test environment"""
        try:
            self.root.destroy()
        except tk.TclError:
            pass
        
        # Clean up temp files
        try:
            self.test_data_file.unlink()
            Path(self.temp_dir).rmdir()
        except (FileNotFoundError, OSError):
            pass
    
    def test_user_workflow_startup_and_project_management(self):
        """AQT-001: Test complete user workflow from startup to project management"""
        print("\n=== AQT-001: User Startup & Project Management Workflow ===")
        
        # Step 1: User starts application
        try:
            with patch('tick_tock_widget.tick_tock_widget.TickTockWidget.run'):
                widget = TickTockWidget()
                
                # Override data file for testing
                widget.data_manager.data_file = self.test_data_file
                widget.data_manager.load_projects()
                
                print(f"✓ Application started successfully")
                print(f"✓ Loaded {len(widget.data_manager.projects)} projects")
                
                # Step 2: User opens project management window
                widget.show_project_management()
                
                self.assertIsNotNone(widget.project_mgmt_window, "Project management window should be created")
                print(f"✓ Project management window opened")
                
                # Step 3: Verify all projects are visible
                pm_window = widget.project_mgmt_window
                children = pm_window.tree.get_children()
                
                self.assertEqual(len(children), 3, "All 3 projects should be visible in tree")
                print(f"✓ All {len(children)} projects displayed correctly")
                
                # Step 4: Verify project details
                for i, child in enumerate(children):
                    item_text = pm_window.tree.item(child, 'text')
                    item_values = pm_window.tree.item(child, 'values')
                    sub_children = pm_window.tree.get_children(child)
                    
                    print(f"  Project {i+1}: {item_text}")
                    print(f"    DZ Number: {item_values[0]}")
                    print(f"    Name: {item_values[1]}")
                    print(f"    Total Time: {item_values[2]}")
                    print(f"    Sub-activities: {len(sub_children)}")
                    
                    # Verify sub-activities are loaded
                    expected_sub_counts = [3, 2, 2]  # Based on test data
                    self.assertEqual(len(sub_children), expected_sub_counts[i], 
                                   f"Project {i+1} should have {expected_sub_counts[i]} sub-activities")
                
                print(f"✓ All project details verified correctly")
                
        except Exception as e:
            self.fail(f"User workflow test failed: {e}")
    
    def test_large_dataset_performance(self):
        """AQT-002: Test performance with large dataset"""
        print("\n=== AQT-002: Large Dataset Performance Test ===")
        
        # Create large dataset (100 projects with 5 sub-activities each)
        large_data = {"projects": [], "current_project_alias": None, "current_sub_activity_alias": None}
        
        for i in range(100):
            project = {
                "name": f"Large Project {i+1}",
                "dz_number": f"LARGE-{i+1:03d}",
                "alias": f"large{i+1}",
                "sub_activities": [],
                "time_records": {
                    "2025-08-01": {"date": "2025-08-01", "total_seconds": i * 100, "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                }
            }
            
            # Add 5 sub-activities per project
            for j in range(5):
                sub_activity = {
                    "name": f"Sub Activity {j+1}",
                    "alias": f"sub{j+1}",
                    "time_records": {
                        "2025-08-01": {"date": "2025-08-01", "total_seconds": (i * 10) + (j * 100), "last_started": None, "is_running": False, "sub_activity_seconds": {}}
                    }
                }
                project["sub_activities"].append(sub_activity)
            
            large_data["projects"].append(project)
        
        # Write large dataset
        large_data_file = Path(self.temp_dir) / "large_projects.json"
        with open(large_data_file, 'w', encoding='utf-8') as f:
            json.dump(large_data, f)
        
        try:
            # Test loading performance
            start_time = time.time()
            data_manager = ProjectDataManager(str(large_data_file))
            load_success = data_manager.load_projects()
            load_time = time.time() - start_time
            
            self.assertTrue(load_success, "Should successfully load large dataset")
            self.assertEqual(len(data_manager.projects), 100, "Should load all 100 projects")
            print(f"✓ Loaded 100 projects in {load_time:.3f} seconds")
            
            # Test tree population performance
            mock_parent = MagicMock()
            mock_parent.root = self.root
            
            theme = {'name': 'Test', 'bg': '#000000', 'fg': '#FFFFFF', 'accent': '#FF0000'}
            
            with patch.object(tk.Toplevel, 'mainloop'):
                start_time = time.time()
                pm_window = ProjectManagementWindow(mock_parent, data_manager, None, theme)
                population_time = time.time() - start_time
                
                print(f"✓ Populated tree with 100 projects in {population_time:.3f} seconds")
                
                # Verify all projects are shown
                children = pm_window.tree.get_children()
                self.assertEqual(len(children), 100, "Tree should show all 100 projects")
                
                # Verify sub-activities are loaded
                total_sub_activities = sum(len(pm_window.tree.get_children(child)) for child in children)
                self.assertEqual(total_sub_activities, 500, "Should have 500 total sub-activities (100 * 5)")
                
                print(f"✓ Verified all 500 sub-activities are displayed correctly")
                
                # Performance benchmarks
                self.assertLess(load_time, 5.0, "Data loading should complete within 5 seconds")
                self.assertLess(population_time, 10.0, "Tree population should complete within 10 seconds")
                
                print(f"✓ Performance benchmarks met (load: {load_time:.3f}s, populate: {population_time:.3f}s)")
                
        finally:
            try:
                large_data_file.unlink()
            except FileNotFoundError:
                pass
    
    def test_stress_test_rapid_operations(self):
        """AQT-003: Stress test with rapid operations"""
        print("\n=== AQT-003: Stress Test - Rapid Operations ===")
        
        data_manager = ProjectDataManager(str(self.test_data_file))
        data_manager.load_projects()
        
        mock_parent = MagicMock()
        mock_parent.root = self.root
        
        theme = {'name': 'Test', 'bg': '#000000', 'fg': '#FFFFFF', 'accent': '#FF0000'}
        
        with patch.object(tk.Toplevel, 'mainloop'):
            pm_window = ProjectManagementWindow(mock_parent, data_manager, None, theme)
            
            # Rapid tree repopulation (simulates user rapidly switching views)
            start_time = time.time()
            for i in range(50):
                pm_window.populate_projects()
                
                # Verify consistency after each repopulation
                children = pm_window.tree.get_children()
                self.assertEqual(len(children), 3, f"Iteration {i+1}: Should always show 3 projects")
                
                # Verify first project still has sub-activities
                if children:
                    sub_children = pm_window.tree.get_children(children[0])
                    self.assertEqual(len(sub_children), 3, f"Iteration {i+1}: First project should have 3 sub-activities")
            
            stress_time = time.time() - start_time
            print(f"✓ Completed 50 rapid repopulations in {stress_time:.3f} seconds")
            print(f"✓ Average time per population: {stress_time/50:.4f} seconds")
            
            # Final verification
            final_children = pm_window.tree.get_children()
            self.assertEqual(len(final_children), 3, "Final state should show 3 projects")
            
            print(f"✓ Data integrity maintained throughout stress test")
    
    def test_memory_leak_detection(self):
        """AQT-004: Memory leak detection test"""
        print("\n=== AQT-004: Memory Leak Detection ===")
        
        import gc
        
        # Get initial memory baseline
        gc.collect()
        initial_objects = len(gc.get_objects())
        
        data_manager = ProjectDataManager(str(self.test_data_file))
        data_manager.load_projects()
        
        mock_parent = MagicMock()
        mock_parent.root = self.root
        
        theme = {'name': 'Test', 'bg': '#000000', 'fg': '#FFFFFF', 'accent': '#FF0000'}
        
        # Create and destroy multiple windows
        for iteration in range(10):
            with patch.object(tk.Toplevel, 'mainloop'):
                pm_window = ProjectManagementWindow(mock_parent, data_manager, None, theme)
                
                # Perform operations
                pm_window.populate_projects()
                
                # Verify functionality
                children = pm_window.tree.get_children()
                self.assertEqual(len(children), 3, f"Iteration {iteration+1}: Should show 3 projects")
                
                # Simulate window destruction
                if hasattr(pm_window, 'window'):
                    try:
                        pm_window.window.destroy()
                    except tk.TclError:
                        pass
                
                del pm_window
                gc.collect()
        
        # Check for memory leaks
        gc.collect()
        final_objects = len(gc.get_objects())
        object_growth = final_objects - initial_objects
        
        print(f"✓ Initial objects: {initial_objects}")
        print(f"✓ Final objects: {final_objects}")
        print(f"✓ Object growth: {object_growth}")
        
        # Allow for some object growth, but not excessive
        self.assertLess(object_growth, 1000, 
                       f"Object growth ({object_growth}) should be minimal to avoid memory leaks")
        
        print(f"✓ Memory leak test passed - growth within acceptable limits")
    
    def test_error_recovery_scenarios(self):
        """AQT-005: Error recovery scenarios"""
        print("\n=== AQT-005: Error Recovery Scenarios ===")
        
        # Test 1: Corrupted data recovery
        print("Testing corrupted data recovery...")
        corrupted_data = '{"projects": [{"name": "Corrupted", invalid_json}]}'
        corrupted_file = Path(self.temp_dir) / "corrupted.json"
        
        with open(corrupted_file, 'w', encoding='utf-8') as f:
            f.write(corrupted_data)
        
        data_manager = ProjectDataManager(str(corrupted_file))
        
        # Should handle corrupted data gracefully
        try:
            load_result = data_manager.load_projects()
            # Either loads successfully with fallback or fails gracefully
            if load_result:
                projects_count = len(data_manager.projects) if data_manager.projects else 0
                print(f"✓ Graceful fallback: loaded {projects_count} projects from corrupted data")
            else:
                print(f"✓ Graceful failure: data manager handled corruption properly")
        except Exception as e:
            # Should not raise unhandled exceptions
            self.fail(f"Data manager should handle corrupted data gracefully: {e}")
        
        # Test 2: Missing file recovery
        print("Testing missing file recovery...")
        missing_file = Path(self.temp_dir) / "nonexistent.json"
        data_manager2 = ProjectDataManager(str(missing_file))
        
        try:
            load_result2 = data_manager2.load_projects()
            print(f"✓ Missing file handled gracefully: load_result={load_result2}")
        except Exception as e:
            self.fail(f"Data manager should handle missing files gracefully: {e}")
        
        # Test 3: Project management window with bad data
        print("Testing project management window with problematic data...")
        mock_parent = MagicMock()
        mock_parent.root = self.root
        
        theme = {'name': 'Test', 'bg': '#000000', 'fg': '#FFFFFF', 'accent': '#FF0000'}
        
        with patch.object(tk.Toplevel, 'mainloop'):
            try:
                pm_window = ProjectManagementWindow(mock_parent, data_manager, None, theme)
                pm_window.populate_projects()
                print(f"✓ Project management window handled problematic data gracefully")
            except Exception as e:
                self.fail(f"Project management window should handle bad data gracefully: {e}")
        
        # Cleanup
        try:
            corrupted_file.unlink()
        except FileNotFoundError:
            pass
        
        print(f"✓ All error recovery scenarios passed")


if __name__ == '__main__':
    # Run with high verbosity to see detailed test progress
    unittest.main(verbosity=2, buffer=True)
